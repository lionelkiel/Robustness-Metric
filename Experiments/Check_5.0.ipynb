{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:30:10.336340700Z",
     "start_time": "2024-01-20T12:30:05.904307500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "from Helper.ImportDatasets import df_epsilon, df_epsilon_crit\n",
    "from Method.calculate_distribution_a import distribution_a"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "In this notebook we calculate the distribution of a for different networks multiple times. Then we check if this makes sense.\n",
    "\n",
    "We do this by taking all the actual critical epsilons and checking how many are lower than the calculated aread, in the area, and above it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fc38123ec529fa1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We pick sigma, delta, network and number of samples. Although delta doesn't matter much as the region of a we use is large enough to quickly find a solution where prob = 1\n",
    "\"\"\"\n",
    "def run(network, ani = False, shuffle = False, step_size_a = 0.001, sigma = 0.05, n_samples = 1000, n_a_samples = 100, uncertainty = 0.02):\n",
    "    delta = 0.05\n",
    "    \n",
    "    # Get the network and test set, then split the images\n",
    "    df_for_network = df_epsilon[df_epsilon['network'] == network]\n",
    "    df_for_network = df_for_network[df_for_network['ds'] == 'test']\n",
    "    df_per_image = [df_for_network[df_for_network['image'] == i] for i in df_for_network['image'].unique()]\n",
    "    \n",
    "    # We find the distribution of 'a' for the following bins, number represents left side of bin\n",
    "    a = torch.arange(step_size_a,0.4,step_size_a)\n",
    "    \n",
    "    # We keep track of the distributions of 'a' and its max probability\n",
    "    distributions_of_a = []\n",
    "    \n",
    "    # We keep track of what bins of 'a' we use\n",
    "    a_bins = []\n",
    "    \n",
    "    # Initialize D (dataset) and the default value to put in if we don't find elligible epsilons\n",
    "    D = torch.tensor([[],[]],dtype=torch.float32)\n",
    "    default = torch.tensor([[0],[0.4]],dtype=torch.float32)\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(df_per_image)\n",
    "    \n",
    "    for i,image in enumerate(df_per_image):\n",
    "        # We put in the default value first and then change it to the lower and upper bound of the image\n",
    "        D = torch.cat((D,default),dim=1)\n",
    "        \n",
    "        # unsat means epsilon >, thus lower bound\n",
    "        lower_bound = np.max(image[image['result']=='unsat']['epsilon'].values)\n",
    "        # sat means epsilon <, thus upper bound\n",
    "        upper_bound = np.min(image[image['result']=='sat']['epsilon'].values)\n",
    "        D[0,-1] = lower_bound\n",
    "        D[1,-1] = upper_bound\n",
    "        \n",
    "        print(f\"image {i+1}\")\n",
    "        \n",
    "        # Sample in our bins of 'a', 100 samples are taken per bin\n",
    "        a_samples = torch.rand(n_a_samples,*a.shape)*step_size_a+a\n",
    "        # We calculate the distribution of each sample\n",
    "        distr = distribution_a(a_samples,D,sigma,n_samples)\n",
    "        max_distr = torch.max(distr)\n",
    "        distributions_of_a.append(distr)\n",
    "        a_bins.append(a)\n",
    "        \n",
    "        # If the distribution of 'a' becomes too peaked to fit in the range of a that has been given we are also satisfied as we know 'a' is in a small enough region\n",
    "        if torch.isnan(max_distr):\n",
    "           distributions_of_a.pop()\n",
    "           a_bins.pop()\n",
    "           print('found: region is too small')\n",
    "           break\n",
    "        \n",
    "        # We adapt the area in which we search for 'a' based on the distribution\n",
    "        indices = torch.where(distr != 0)[0]\n",
    "        left_bound_ind = torch.min(indices)\n",
    "        right_bound_ind = torch.max(indices)\n",
    "        \n",
    "        # We update the bounds\n",
    "        left_bound = a[left_bound_ind]\n",
    "        right_bound = a[right_bound_ind]\n",
    "        \n",
    "        # We check if the required uncertainty has been reached\n",
    "        if right_bound-left_bound < 2*uncertainty:\n",
    "            print('found: uncertainty reached')\n",
    "            break\n",
    "        \n",
    "        # We check if we have attained a probability of at least 1-delta\n",
    "        if max_distr > 1-delta:\n",
    "            print('found')\n",
    "            break\n",
    "        \n",
    "        # We update the range of 'a' we search in\n",
    "        step_size_a = (right_bound-left_bound)/400\n",
    "        a = torch.arange(left_bound,right_bound,step_size_a)\n",
    "        \n",
    "    \n",
    "    if ani:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "        ax.set_ylim(0, 0.1)\n",
    "        ax.set_xlim(0,0.2)\n",
    "        line, = ax.plot(a, np.tile(0,len(a)))\n",
    "        \n",
    "        \n",
    "        def animate(i):\n",
    "            line.set_ydata(distributions_of_a[i])  # update the data.\n",
    "            line.set_xdata(a_bins[i])\n",
    "            return line,\n",
    "        \n",
    "        \n",
    "        ani = animation.FuncAnimation(\n",
    "            fig, animate, frames=len(distributions_of_a), interval=20, blit=True, save_count=50)\n",
    "        \n",
    "        # To save the animation, use e.g.\n",
    "        #\n",
    "        ani.save(network+\".gif\")\n",
    "    \n",
    "    return distributions_of_a, a_bins"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:34:08.848252600Z",
     "start_time": "2024-01-20T12:34:08.839777100Z"
    }
   },
   "id": "110574aa72f2788b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "networks = df_epsilon['network'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:34:12.291559500Z",
     "start_time": "2024-01-20T12:34:12.277060100Z"
    }
   },
   "id": "9ebf9b66d6c73005"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "found: region is too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lkiel\\AppData\\Local\\Temp\\ipykernel_13860\\1014375679.py:94: UserWarning: You passed in an explicit save_count=50 which is being ignored in favor of frames=26.\n",
      "  ani = animation.FuncAnimation(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = networks[0]\n",
    "distr, a_bins = run(network, uncertainty = 0.002, ani=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:40:50.503920200Z",
     "start_time": "2024-01-20T12:37:46.601030600Z"
    }
   },
   "id": "d60700e4d74f16be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take all critical epsilons and calculate if they are in the area, below it, or above it\n",
    "# We ignore that the critical epsilon is an area as it would complicate things for now\n",
    "df_for_network = df_epsilon_crit[df_epsilon_crit['network'] == network]\n",
    "df_for_network = df_for_network[df_for_network['ds'] == 'test']\n",
    "crit_epsilons = df_for_network['Epsilon'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:50:30.090869600Z",
     "start_time": "2024-01-20T12:50:30.087866700Z"
    }
   },
   "id": "4fe81d69a0a65bfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Total = crit_epsilons.shape[0]\n",
    "under = np.sum(crit_epsilons < left_bound.numpy())\n",
    "over = np.sum(crit_epsilons > right_bound.numpy())\n",
    "in_between = Total - under - over\n",
    "print(f\"Percentage under: {np.round((under/Total)*100,2)}%, Percentage in between: {np.round((in_between/Total)*100,2)}%, Percentage over: {np.round((over/Total)*100,2)}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-20T12:50:30.095874100Z"
    }
   },
   "id": "903e4e8a6a7f0af7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_percentages(distr, a_bins):\n",
    "    \n",
    "    indices = torch.where(distr[-1] == 0)[0]\n",
    "    split_arrays = np.split(indices,torch.where(torch.diff(indices) != 1)[0]+1)\n",
    "    # Check wether left and right arrays exist\n",
    "    if len(split_arrays) == 1:\n",
    "        arr = split_arrays[0]\n",
    "        if arr.shape[0] == 0:\n",
    "            left_bound_ind = 0\n",
    "            right_bound_ind = -1\n",
    "        elif torch.min(arr) == 0:\n",
    "            left_bound_ind = torch.max(arr)\n",
    "            right_bound_ind = -1\n",
    "        else:\n",
    "            left_bound_ind = 0\n",
    "            right_bound_ind = torch.min(arr)\n",
    "    elif len(split_arrays) == 2:\n",
    "        left_bound_ind = torch.max(split_arrays[0])\n",
    "        right_bound_ind = torch.min(split_arrays[1])\n",
    "    else:\n",
    "        print('error? 2')\n",
    "        print(split_arrays)\n",
    "        left_bound_ind = torch.max(split_arrays[0])\n",
    "        right_bound_ind = torch.min(split_arrays[-1])\n",
    "    \n",
    "    # We update the bounds\n",
    "    left_bound = a_bins[-1][left_bound_ind]\n",
    "    right_bound = a_bins[-1][right_bound_ind]\n",
    "    \n",
    "    # Take all critical epsilons and calculate if they are in the area, below it, or above it\n",
    "    # We ignore that the critical epsilon is an area as it would complicate things for now\n",
    "    df_for_network = df_epsilon_crit[df_epsilon_crit['network'] == network]\n",
    "    df_for_network = df_for_network[df_for_network['ds'] == 'test']\n",
    "    crit_epsilons = df_for_network['Epsilon'].to_numpy()\n",
    "    \n",
    "    Total = crit_epsilons.shape[0]\n",
    "    under = np.sum(crit_epsilons < left_bound.numpy())\n",
    "    over = np.sum(crit_epsilons > right_bound.numpy())\n",
    "    in_between = Total - under - over\n",
    "    print(f\"Percentage under: {np.round((under/Total)*100,2)}%, Percentage in between: {np.round((in_between/Total)*100,2)}%, Percentage over: {np.round((over/Total)*100,2)}%\")\n",
    "    return np.round((under/Total)*100,2), np.round((in_between/Total)*100,2), np.round((over/Total)*100,2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:50:30.118895300Z",
     "start_time": "2024-01-20T12:50:30.099878200Z"
    }
   },
   "id": "2ce495fa7273b0d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84572184cb7dc50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = networks[0]\n",
    "distr, a_bins = run(network, uncertainty = 0.02, ani=False)\n",
    "calculate_percentages(distr, a_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-20T12:50:30.103880900Z"
    }
   },
   "id": "1a2179e2e6afce6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = networks[0]\n",
    "distr, a_bins = run(network, uncertainty = 0.002, ani=False)\n",
    "calculate_percentages(distr, a_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-20T12:50:30.104882200Z"
    }
   },
   "id": "946c44e27943f33b"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172]), tensor([176]), tensor([254]), tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399])]\n",
      "image 29\n",
      "found: region is too small\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172]), tensor([176]), tensor([254]), tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399])]\n",
      "Percentage under: 8.08%, Percentage in between: 4.04%, Percentage over: 87.88%\n",
      "1/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 4.04%, Percentage in between: 7.07%, Percentage over: 88.89%\n",
      "2/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 4.04%, Percentage in between: 14.14%, Percentage over: 81.82%\n",
      "3/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "image 29\n",
      "image 30\n",
      "image 31\n",
      "found: region is too small\n",
      "Percentage under: 5.05%, Percentage in between: 13.13%, Percentage over: 81.82%\n",
      "4/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 4.04%, Percentage in between: 8.08%, Percentage over: 87.88%\n",
      "5/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 6.06%, Percentage in between: 12.12%, Percentage over: 81.82%\n",
      "6/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "image 29\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175]), tensor([177]), tensor([184]), tensor([261]), tensor([263, 264, 265]), tensor([267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399])]\n",
      "image 30\n",
      "found: region is too small\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175]), tensor([177]), tensor([184]), tensor([261]), tensor([263, 264, 265]), tensor([267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
      "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
      "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "        393, 394, 395, 396, 397, 398, 399])]\n",
      "Percentage under: 8.08%, Percentage in between: 3.03%, Percentage over: 88.89%\n",
      "7/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 4.04%, Percentage in between: 7.07%, Percentage over: 88.89%\n",
      "8/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "found: region is too small\n",
      "Percentage under: 4.04%, Percentage in between: 14.14%, Percentage over: 81.82%\n",
      "9/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "image 29\n",
      "image 30\n",
      "found: region is too small\n",
      "Percentage under: 8.08%, Percentage in between: 10.1%, Percentage over: 81.82%\n",
      "10/10 done\n"
     ]
    }
   ],
   "source": [
    "network = networks[0]\n",
    "final_distr = []\n",
    "final_bins = []\n",
    "percentages = []\n",
    "for i in range(10):\n",
    "    distr, bins = run(network, ani=False, shuffle = True, uncertainty= 0.002)\n",
    "    temp_distr = distr[-1].numpy()\n",
    "    temp_bins = bins[-1].numpy()\n",
    "    final_distr.append(temp_distr)\n",
    "    final_bins.append(temp_bins)\n",
    "    percentages.append(calculate_percentages(distr, bins))\n",
    "    print(f\"{i+1}/10 done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T16:47:57.439680200Z",
     "start_time": "2023-12-20T16:21:08.477466100Z"
    }
   },
   "id": "fc588da0a847d3e3"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "found: region is too small\n",
      "Percentage under: 6.19%, Percentage in between: 19.59%, Percentage over: 74.23%\n",
      "1/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "found: region is too small\n",
      "Percentage under: 6.19%, Percentage in between: 13.4%, Percentage over: 80.41%\n",
      "2/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "found: region is too small\n",
      "Percentage under: 1.03%, Percentage in between: 6.19%, Percentage over: 92.78%\n",
      "3/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "found: region is too small\n",
      "Percentage under: 1.03%, Percentage in between: 14.43%, Percentage over: 84.54%\n",
      "4/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "image 29\n",
      "image 30\n",
      "found: region is too small\n",
      "Percentage under: 12.37%, Percentage in between: 16.49%, Percentage over: 71.13%\n",
      "5/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210]), tensor([212, 213]), tensor([215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256,\n",
      "        257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
      "        271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
      "        285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
      "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
      "        327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
      "        341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "        355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
      "        369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "        383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
      "        397, 398, 399, 400])]\n",
      "image 25\n",
      "found: region is too small\n",
      "error? 2\n",
      "[tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210]), tensor([212, 213]), tensor([215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
      "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
      "        243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256,\n",
      "        257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
      "        271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
      "        285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
      "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
      "        327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
      "        341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "        355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
      "        369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "        383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
      "        397, 398, 399, 400])]\n",
      "Percentage under: 7.22%, Percentage in between: 0.0%, Percentage over: 92.78%\n",
      "6/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "found: region is too small\n",
      "Percentage under: 7.22%, Percentage in between: 10.31%, Percentage over: 82.47%\n",
      "7/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "found: region is too small\n",
      "Percentage under: 6.19%, Percentage in between: 1.03%, Percentage over: 92.78%\n",
      "8/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "found: region is too small\n",
      "Percentage under: 4.12%, Percentage in between: 26.8%, Percentage over: 69.07%\n",
      "9/10 done\n",
      "image 1\n",
      "image 2\n",
      "image 3\n",
      "image 4\n",
      "image 5\n",
      "image 6\n",
      "image 7\n",
      "image 8\n",
      "image 9\n",
      "image 10\n",
      "image 11\n",
      "image 12\n",
      "image 13\n",
      "image 14\n",
      "image 15\n",
      "image 16\n",
      "image 17\n",
      "image 18\n",
      "image 19\n",
      "image 20\n",
      "image 21\n",
      "image 22\n",
      "image 23\n",
      "image 24\n",
      "image 25\n",
      "image 26\n",
      "image 27\n",
      "image 28\n",
      "error? 2\n",
      "[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]), tensor([324]), tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399])]\n",
      "image 29\n",
      "found: region is too small\n",
      "error? 2\n",
      "[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]), tensor([324]), tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399])]\n",
      "Percentage under: 7.22%, Percentage in between: 12.37%, Percentage over: 80.41%\n",
      "10/10 done\n"
     ]
    }
   ],
   "source": [
    "network = networks[-1]\n",
    "final_distr = []\n",
    "final_bins = []\n",
    "percentages = []\n",
    "for i in range(10):\n",
    "    distr, bins = run(network, ani=False, shuffle = True, uncertainty= 0.002)\n",
    "    temp_distr = distr[-1].numpy()\n",
    "    temp_bins = bins[-1].numpy()\n",
    "    final_distr.append(temp_distr)\n",
    "    final_bins.append(temp_bins)\n",
    "    percentages.append(calculate_percentages(distr, bins))\n",
    "    print(f\"{i+1}/10 done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T17:08:35.531030900Z",
     "start_time": "2023-12-20T16:47:57.514748500Z"
    }
   },
   "id": "46d1c2863424fb61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "50ac5099ad3f8f47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
